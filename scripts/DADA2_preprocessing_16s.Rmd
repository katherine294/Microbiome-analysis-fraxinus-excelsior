---
title: "DADA2 pre-processing of 16S sequences"
author: "Katherine Hinton"
output: "html_document"
date: "2025-06-05"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load packages --------------------------------------------------------------
```{r}
library(dada2)
library(phyloseq)
library(Biostrings)
library(ShortRead)
library(ggplot2)
library(vegan)
library(tidyverse)
library(ggpubr)
library(plyr)
library(microbiome)
library(devtools)

options(bitmapType = "cairo")

# Check versions (optional)
packageVersion("dada2")
packageVersion("phyloseq")
```

Define paths ---------------------------------------------------------------
```{r}
setwd("/rds/homes/k/kgh742/psf_wgs_project/02.MicrobiomeAnalysis/16S_Raw")
path <- getwd()
list.files(path)
```

Pair reads and extract sample names ----------------------------------------
```{r}
fnFs <- sort(list.files(path, pattern = "_1.fastq", full.names = TRUE))
fnRs <- sort(list.files(path, pattern = "_2.fastq", full.names = TRUE))
sample.names <- sapply(strsplit(basename(fnFs), "_1"), `[`, 1)
head(sample.names)

# Quality profiles -----------------------------------------------------------
plotQualityProfile(fnFs[1:4])
plotQualityProfile(fnRs[1:4])
```

Filter and trim ------------------------------------------------------------
```{r}
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- names(filtRs) <- sample.names

out <- filterAndTrim(
  fnFs, filtFs, fnRs, filtRs,
  truncLen = c(180, 220),
  maxN = 0, maxEE = 1, truncQ = 2, rm.phix = TRUE,
  compress = TRUE, multithread = TRUE
)
head(out)
```

Learn error rates ----------------------------------------------------------
```{r}
errF <- learnErrors(filtFs, multithread = TRUE)
errR <- learnErrors(filtRs, multithread = TRUE)

plotErrors(errF, nominalQ = TRUE)
plotErrors(errR, nominalQ = TRUE)
```
Denoise reads --------------------------------------------------------------
```{r}
derepFs <- derepFastq(filtFs, verbose = TRUE)
derepRs <- derepFastq(filtRs, verbose = TRUE)
names(derepFs) <- names(derepRs) <- sample.names

dadaFs <- dada(derepFs, err = errF, multithread = TRUE)
dadaRs <- dada(derepRs, err = errR, multithread = TRUE)
```

Merge paired reads ---------------------------------------------------------
```{r}
mergers <- mergePairs(dadaFs, filtFs, dadaRs, filtRs, verbose = TRUE)
seqtab <- makeSequenceTable(mergers)

dim(seqtab)
table(nchar(getSequences(seqtab)))
```

Remove chimeras ------------------------------------------------------------
```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method = "consensus", multithread = TRUE)
dim(seqtab.nochim)
sum(seqtab.nochim) / sum(seqtab)
```

Track read counts through pipeline -----------------------------------------
```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(
  out,
  sapply(dadaFs, getN),
  sapply(dadaRs, getN),
  sapply(mergers, getN),
  rowSums(seqtab.nochim)
)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
```

Assign taxonomy (SILVA) ----------------------------------------------------
```{r}
taxa <- assignTaxonomy(
  seqtab.nochim,
  "/rds/projects/j/jacksorw-66837/sequencing_working_dir/silva_nr99_v138.2_toGenus_trainset.fa.gz",
  multithread = TRUE
)

taxa <- addSpecies(
  taxa,
  "/rds/projects/j/jacksorw-66837/sequencing_working_dir/silva_v138.2_assignSpecies.fa.gz"
)
```

Save outputs ---------------------------------------------------------------
```{r}
saveRDS(taxa, "taxa_table.rds")
write.csv(seqtab.nochim, "ASV_table.csv")
write.csv(taxa, "tax_table.csv")

sq <- getSequences(seqtab.nochim)
names(sq) <- paste0("Abundance=", colSums(seqtab.nochim))
writeFasta(sq, file = "ASVs_abundance.fasta")

# Summarise dataset statistics -----------------------------------------------
summarise_dada2_dataset <- function(track, seqtab.nochim) {
  retained_percent <- 100 * track[, "nonchim"] / track[, "input"]
  asvs_per_sample <- rowSums(seqtab.nochim > 0)
  
  data.frame(
    Samples = nrow(track),
    Raw_Reads = sprintf("%.0f ± %.0f", mean(track[, "input"]), sd(track[, "input"])),
    Merged_Reads = sprintf("%.0f ± %.0f", mean(track[, "merged"]), sd(track[, "merged"])),
    Percent_Retained = sprintf("%.1f%% ± %.1f%%", mean(retained_percent), sd(retained_percent)),
    ASVs_per_Sample = sprintf("%.0f ± %.0f", mean(asvs_per_sample), sd(asvs_per_sample)),
    Total_ASVs = ncol(seqtab.nochim)
  )
}

summary_table <- summarise_dada2_dataset(track, seqtab.nochim)
print(summary_table)
write.csv(summary_table, "DADA2_summary_16S.csv", row.names = FALSE)

```

